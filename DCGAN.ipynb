{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "use-DCGAN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8tuaztjLyX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37qsdeWtMMPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/gdrive/My Drive/DCGAN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIZJbstcMahp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/triwave33/GAN.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNZlZG1zKS_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Convolution2D\n",
        "from keras.models import Sequential, Model, load_model\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VI8lLWZKYXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGAN():\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.path = \"/content/gdrive/My Drive/DCGAN/dcgan_generated_images/\"\n",
        "        #mnistデータ用の入力データサイズ\n",
        "        self.img_rows = 28 \n",
        "        self.img_cols = 28\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        \n",
        "        # 潜在変数の次元数 \n",
        "        self.z_dim = 5\n",
        "\n",
        "        # 画像保存の際の列、行数\n",
        "        self.row = 5\n",
        "        self.col = 5\n",
        "        self.row2 = 1 # 連続潜在変数用\n",
        "        self.col2 = 10# 連続潜在変数用 \n",
        "        \n",
        "        # 画像生成用の固定された入力潜在変数\n",
        "        self.noise_fix1 = np.random.normal(0, 1, (self.row * self.col, self.z_dim)) \n",
        "        # 連続的に潜在変数を変化させる際の開始、終了変数\n",
        "        self.noise_fix2 = np.random.normal(0, 1, (1, self.z_dim))\n",
        "        self.noise_fix3 = np.random.normal(0, 1, (1, self.z_dim))\n",
        "\n",
        "        # 横軸がiteration数のプロット保存用np.ndarray\n",
        "        self.g_loss_array = np.array([])\n",
        "        self.d_loss_array = np.array([])\n",
        "        self.d_accuracy_array = np.array([])\n",
        "        self.d_predict_true_num_array = np.array([])\n",
        "        self.c_predict_class_list = []\n",
        "\n",
        "        discriminator_optimizer = Adam(lr=1e-5, beta_1=0.1)\n",
        "        combined_optimizer = Adam(lr=2e-4, beta_1=0.5)\n",
        "\n",
        "        # discriminatorモデル\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy', \n",
        "            optimizer=discriminator_optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "        # Generatorモデル\n",
        "        self.generator = self.build_generator()\n",
        "        # generatorは単体で学習しないのでコンパイルは必要ない\n",
        "        #self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "        self.combined = self.build_combined1()\n",
        "        #self.combined = self.build_combined2()\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=combined_optimizer)\n",
        "\n",
        "        # Classifierモデル\n",
        "        self.classifier = self.build_classifier()\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        noise_shape = (self.z_dim,)\n",
        "        model = Sequential()\n",
        "        model.add(Dense(1024, input_shape=noise_shape))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dense(128*7*7))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Reshape((7,7,128), input_shape=(128*7*7,)))\n",
        "        model.add(UpSampling2D((2,2)))\n",
        "        model.add(Convolution2D(64,5,5,border_mode='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(UpSampling2D((2,2)))\n",
        "        model.add(Convolution2D(1,5,5,border_mode='same'))\n",
        "        model.add(Activation('tanh'))\n",
        "        model.summary()\n",
        "        return model\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Convolution2D(64,5,5, subsample=(2,2),\\\n",
        "                  border_mode='same', input_shape=img_shape))\n",
        "        model.add(LeakyReLU(0.2))\n",
        "        model.add(Convolution2D(128,5,5,subsample=(2,2)))\n",
        "        model.add(LeakyReLU(0.2))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(256))\n",
        "        model.add(LeakyReLU(0.2))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(1))\n",
        "        model.add(Activation('sigmoid'))   \n",
        "        return model\n",
        "    \n",
        "    def build_combined1(self):\n",
        "        self.discriminator.trainable = False\n",
        "        model = Sequential([self.generator, self.discriminator])\n",
        "        return model\n",
        "\n",
        "    def build_combined2(self):\n",
        "        z = Input(shape=(self.z_dim,))\n",
        "        img = self.generator(z)\n",
        "        self.discriminator.trainable = False\n",
        "        valid = self.discriminator(img)\n",
        "        model = Model(z, valid)\n",
        "        model.summary()\n",
        "        return model\n",
        "\n",
        "    def build_classifier(self):\n",
        "        model = load_model(\"cnn_model.h5\")\n",
        "        model.load_weights('cnn_weight.h5')\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "    def train(self, epochs, batch_size=128, save_interval=50):\n",
        "\n",
        "        # mnistデータの読み込み\n",
        "        (X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "        # 値を-1 to 1に規格化\n",
        "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "        X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "        half_batch = int(batch_size / 2)\n",
        "\n",
        "        self.g_loss_array = np.zeros(epochs)\n",
        "        self.d_loss_array = np.zeros(epochs)\n",
        "        self.d_accuracy_array = np.zeros(epochs)\n",
        "        self.d_predict_true_num_array = np.zeros(epochs)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            # ---------------------\n",
        "            #  Discriminatorの学習\n",
        "            # ---------------------\n",
        "\n",
        "            # バッチサイズの半数をGeneratorから生成\n",
        "            noise = np.random.normal(0, 1, (half_batch, self.z_dim))\n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "\n",
        "            # バッチサイズの半数を教師データからピックアップ\n",
        "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "            imgs = X_train[idx]\n",
        "\n",
        "            # discriminatorを学習\n",
        "            # 本物データと偽物データは別々に学習させる\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
        "            # それぞれの損失関数を平均\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # discriminatorの予測（本物と偽物が半々のミニバッチ）\n",
        "            d_predict = self.discriminator.predict_classes(np.concatenate([gen_imgs,imgs]), verbose=0)\n",
        "            d_predict = np.sum(d_predict)\n",
        "\n",
        "# classifierの予測\n",
        "            c_predict = self.classifier.predict_classes(np.concatenate([gen_imgs,imgs]), verbose=0)\n",
        "\n",
        "\n",
        "            # ---------------------\n",
        "            #  Generatorの学習\n",
        "            # ---------------------\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
        "\n",
        "\n",
        "            # 生成データの正解ラベルは本物（1） \n",
        "            valid_y = np.array([1] * batch_size)\n",
        "\n",
        "            # Train the generator\n",
        "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
        "\n",
        "\n",
        "            # 進捗の表示\n",
        "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "            # np.ndarrayにloss関数を格納\n",
        "            self.g_loss_array[epoch] = g_loss\n",
        "            self.d_loss_array[epoch] = d_loss[0]\n",
        "            self.d_accuracy_array[epoch] = 100*d_loss[1]\n",
        "            self.d_predict_true_num_array[epoch] = d_predict\n",
        "            self.c_predict_class_list.append(c_predict)\n",
        "\n",
        "            if epoch % save_interval == 0:\n",
        "                \n",
        "                # 毎回異なる乱数から画像を生成\n",
        "                self.save_imgs(self.row, self.col, epoch, '', noise)\n",
        "                # 毎回同じ値から画像を生成\n",
        "                self.save_imgs(self.row, self.col, epoch, 'fromFixedValue', self.noise_fix1)\n",
        "                # 二つの潜在変数の間の遷移画像を生成\n",
        "                total_images = self.row*self.col\n",
        "                noise_trans = np.zeros((total_images, self.z_dim))\n",
        "                for i in range(total_images):\n",
        "                    t = (i*1.)/((total_images-1)*1.)\n",
        "                    noise_trans[i,:] = t * self.noise_fix2 + (1-t) * self.noise_fix3\n",
        "                self.save_imgs(self.row2, self.col2, epoch, 'trans', noise_trans)\n",
        "\n",
        "                # classifierに生成画像のクラス識別をさせる（10000サンプル）\n",
        "                noise = np.random.normal(0, 1, (10000, self.z_dim))\n",
        "                class_res = self.classifier.predict_classes(self.generator.predict(noise), verbose=0)\n",
        "                # plot histgram\n",
        "                plt.hist(class_res)\n",
        "                plt.savefig(self.path + \"mnist_hist_%d.png\" % epoch)\n",
        "                plt.ylim(0,2000)\n",
        "                plt.close()\n",
        "\n",
        "\n",
        "       \n",
        "                # 学習結果をプロット\n",
        "                fig, ax = plt.subplots(4,1, figsize=(8.27,11.69))\n",
        "                ax[0].plot(self.g_loss_array[:epoch])\n",
        "                ax[0].set_title(\"g_loss\")\n",
        "                ax[1].plot(self.d_loss_array[:epoch])\n",
        "                ax[1].set_title(\"d_loss\")\n",
        "                ax[2].plot(self.d_accuracy_array[:epoch])\n",
        "                ax[2].set_title(\"d_accuracy\")\n",
        "                ax[3].plot(self.d_predict_true_num_array[:epoch])\n",
        "                ax[3].set_title(\"d_predict_true_num_array\")\n",
        "                fig.suptitle(\"epoch: %5d\" % epoch)\n",
        "                fig.savefig(self.path + \"training_%d.png\" % epoch)\n",
        "                plt.close()\n",
        "\n",
        "        # 重みを保存\n",
        "        self.generator.save_weights(self.path + \"generator_%s.h5\" % epoch)\n",
        "        self.discriminator.save_weights(self.path + \"discriminator_%s.h5\" % epoch)\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "    def save_imgs(self, row, col, epoch, filename, noise):\n",
        "        # row, col\n",
        "        # 生成画像を敷き詰めるときの行数、列数\n",
        "    \n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "    \n",
        "        # 生成画像を0-1に再スケール\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    \n",
        "    \n",
        "        fig, axs = plt.subplots(row, col)\n",
        "        cnt = 0\n",
        "        if row == 1:\n",
        "            for j in range(col):\n",
        "                axs[j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                axs[j].axis('off')\n",
        "                cnt += 1\n",
        "        else:\n",
        "            for i in range(row):\n",
        "                for j in range(col):\n",
        "                    axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                    axs[i,j].axis('off')\n",
        "                    cnt += 1\n",
        "\n",
        "        #fig.savefig(\"images/mnist_%s_%d.png\" % (filename, epoch))\n",
        "        fig.suptitle(\"epoch: %5d\" % epoch)\n",
        "        fig.savefig(self.path + \"mnist_%s_%d.png\" % (filename, epoch))\n",
        "        plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoVd1LQJKEso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    gan = DCGAN()\n",
        "    gan.train(epochs=100000, batch_size=32, save_interval=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}